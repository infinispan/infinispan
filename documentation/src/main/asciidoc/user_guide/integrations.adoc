==  Integrations
Infinispan can be integrated with a number of other projects, as detailed below.

=== Apache Spark

Infinispan provides an link:http://spark.apache.org[Apache Spark] connector capable of exposing caches as an RDD, allowing batch and stream jobs to be run against data stored in Infinispan. For further details, see the link:https://github.com/infinispan/infinispan-spark/blob/master/README.md[Infinispan Spark connector documentation].
Also check the link:https://github.com/infinispan/infinispan-spark/tree/master/examples/twitter/README.md[Docker based Twitter demo].

=== Apache Hadoop

The Infinispan Hadoop connector can be used to expose Infinispan as a Hadoop compliant data source and sink that implements link:https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/InputFormat.html[InputFormat]/link:https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/OutputFormat.html[OutputFormat].
For further details, refer to the full link:https://github.com/infinispan/infinispan-hadoop/blob/master/README.md[documentation].

=== Apache Lucene [[integrations:lucene-directory]]
Infinispan includes a highly scalable distributed link:http://lucene.apache.org[Apache Lucene Directory] implementation.

This directory closely mimics the same semantics of the traditional filesystem and RAM-based directories, being able to work as a drop-in replacement for existing applications using Lucene and providing reliable index sharing and other features of Infinispan like node auto-discovery, automatic failover and rebalancing, optionally transactions, and can be backed by traditional storage solutions as filesystem, databases or cloud store engines.

The implementation extends Lucene's _org.apache.lucene.store.Directory_ so it can be used to _store_ the index in a cluster-wide shared memory, making it easy to distribute the index. Compared to rsync-based replication this solution is suited for use cases in which your application makes frequent changes to the index and you need them to be quickly distributed to all nodes. Consistency levels, synchronicity and guarantees, total elasticity and auto-discovery are all configurable; also changes applied to the index can optionally participate in a JTA transaction, optionally supporting XA transactions with recovery.

Two different _LockFactory_ implementations are provided to guarantee only one _IndexWriter_ at a time will make changes to the index, again implementing the same semantics as when opening an index on a local filesystem. As with other Lucene Directories, you can override the _LockFactory_ if you prefer to use an alternative implementation.

==== Lucene compatibility
Apache Lucene versions 5.5.x

==== Maven dependencies
All you need is _org.infinispan:infinispan-lucene-directory_ :

.pom.xml
[source,xml,subs=attributes+]
----
<dependency>
   <groupId>org.infinispan</groupId>
   <artifactId>infinispan-lucene-directory</artifactId>
   <version>{infinispanversion}</version>
</dependency>

----
==== How to use it

See the below example of using the Infinispan Lucene Directory in order to index and query a single Document:

[source,java]
----
import java.io.IOException;

import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.StringField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.infinispan.lucene.directory.DirectoryBuilder;
import org.infinispan.manager.DefaultCacheManager;

// Create caches that will store the index. Here the Infinispan programmatic configuration is used
DefaultCacheManager defaultCacheManager = new DefaultCacheManager();
Cache metadataCache = defaultCacheManager.getCache("metadataCache");
Cache dataCache = defaultCacheManager.getCache("dataCache");
Cache lockCache = defaultCacheManager.getCache("lockCache");

// Create the directory
Directory directory = DirectoryBuilder.newDirectoryInstance(metadataCache, dataCache, lockCache, indexName).create();

// Use the directory in Lucene
IndexWriterConfig indexWriterConfig = new IndexWriterConfig(new StandardAnalyzer()).setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);

IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig);

// Index a single document
Document doc = new Document();
doc.add(new StringField("field", "value", Field.Store.NO));
indexWriter.addDocument(doc);
indexWriter.close();

// Querying the inserted document
DirectoryReader directoryReader = DirectoryReader.open(directory);
IndexSearcher searcher = new IndexSearcher(directoryReader);
TermQuery query = new TermQuery(new Term("field", "value"));
TopDocs topDocs = searcher.search(query, 10);
System.out.println(topDocs.totalHits);

----

The _indexName_ in the _DirectoryBuilder_ is a unique key to identify your index. It takes the same role as the path did on filesystem based indexes: you can create several different indexes giving them different names. When you use the same _indexName_ in another instance connected to the same network (or instantiated on the same machine, useful for testing) they will join, form a cluster and share all content. Using a different _indexName_ allows you to store different indexes in the same set of Caches.

The _metadataCache_, _dataCache_ and _lockCache_ are the caches that will store the indexes. More details provided below.

New nodes can be added or removed dynamically, making the service administration very easy and also suited for cloud environments: it's simple to react to load spikes, as adding more memory and CPU power to the search system is done by just starting more nodes.


==== Configuration
Infinispan can be configured as LOCAL clustering mode, in which case it will disable clustering features and serve as a cache for the index, or any clustering mode. A transaction manager is not mandatory, but when enabled the changes to the index can participate in transactions.

Batching was required in previous versions, it's not strictly needed anymore.

As pointed out in the javadocs of link:{javadocroot}/org/infinispan/lucene/directory/DirectoryBuilder.html[DirectoryBuilder], it's possible for it to use more than a single cache, using specific configurations for different purposes. Each cache is explained below:

===== Lock Cache
The lock cache is used to store a single entry per index that will function as the directory lock. Given the small storage requirement this cache is usually configured as REPL_SYNC. Example of declarative configuration:

[source,xml]
----
<replicated-cache name="LuceneIndexesLocking" mode="SYNC" remote-timeout="25000">
    <transaction mode="NONE"/>
    <indexing index="NONE" />
    <memory>
       <object size="-1"/>
    </memory>
</replicated-cache>

----
===== Metadata Cache

The metadata cache is used to store information about the files of the directory, such as buffer sizes and number of chunks. It uses more space than the Lock Cache, but not as much as the Data Cache, so using a REPL_SYNC cache should be fine for most cases.
Example of configuration:

[source,xml]
----
<replicated-cache name="LuceneIndexesMetadaData" mode="SYNC" remote-timeout="25000">
    <transaction mode="NONE"/>
    <indexing index="NONE" />
    <memory>
       <object size="-1"/>
    </memory>
</replicated-cache>
----

===== Data Cache

The Infinispan Lucene directory splits large (bigger than the chunkSize configuration) files into chunks and stores them in the Data cache.
This is the largest of the 3 index caches, and both DIST_SYNC/REPL_SYNC cache modes can be used.
Usage of REPL_SYNC offers lower latencies for queries since each node holds the whole index locally; DIST_SYNC, on the other hand, will affect query latency due to remote calls to fetch for chunks, but offers better scalability.

Example of configuration:

[source,xml]
----
<distributed-cache name="LuceneIndexesData" mode="SYNC" remote-timeout="25000">
    <transaction mode="NONE"/>
    <indexing index="NONE" />
    <memory>
       <object size="-1"/>
    </memory>
</distributed-cache>
----

==== Using a CacheLoader
Using a CacheLoader you can have the index content backed up to a permanent storage; you can use a shared store for all nodes or one per node, see <<cache-passivation, cache passivation>> for more details.

When using a CacheLoader to store a Lucene index, to get best write performance you would need to configure the CacheLoader with _async=true_ .

==== Storing the index in a database
It might be useful to store the Lucene index in a relational database; this would be very slow but Infinispan can act as a cache between the application and the JDBC interface, making this configuration useful in both clustered and non-clustered configurations. When storing indexes in a JDBC database, it's suggested to use the _JdbcStringBasedCacheStore_ , which will need this attribute:

[source,xml]
----
<property name="key2StringMapperClass" value="org.infinispan.lucene.LuceneKey2StringMapper" />
----

==== Loading an existing Lucene Index

The _org.infinispan.lucene.cachestore.LuceneCacheLoader_ is an Infinispan CacheLoader able to have Infinispan directly load data from an existing Lucene index into the grid. Currently this supports reading only.

[options="header"]
|===============
|Property|Description|Default
| _location_ |The path where the indexes are stored. Subdirectories (of first level only) should contain the indexes to be loaded, each directory matching the index name attribute of the InfinispanDirectory constructor.|none (mandatory)
| _autoChunkSize_ |A threshold in bytes: if any segment is larger than this, it will be transparently chunked in smaller cache entries up to this size.|32MB

|===============

It's worth noting that the IO operations are delegated to Lucene's standard _org.apache.lucene.store.FSDirectory_ , which will select an optimal approach for the running platform.

Implementing write-through should not be hard: you're welcome to try implementing it.


==== Architectural limitations
This Directory implementation makes it possible to have almost real-time reads across multiple nodes. A fundamental limitation of the Lucene design is that only a single IndexWriter is allowed to make changes on the index: a pessimistic lock is acquired by the writer; this is generally ok as a single IndexWriter _instance_ is very fast and accepts update requests from multiple threads. When sharing the Directory across Infinispan nodes the IndexWriter limitation is not lifted: since you can have only one instance, that reflects in your application as having to apply all changes on the same node. There are several strategies to write from multiple nodes on the same index:

.Index write strategies
* One node writes, the other delegate to it sending messages
* Each node writes on turns
* You application makes sure it will only ever apply index writes on one node

The _Infinispan Lucene Directory_ protects its content by implementing a distributed locking strategy, though this is designed as a last line of defense and is not to be considered an efficient mechanism to coordinate multiple writes: if you don't apply one of the above suggestions and get high write contention from multiple nodes you will likely get timeout exception.

==== Suggestions for optimal performance

===== JGroups and networking stack
JGroups manages all network IO and as such it is a critical component to tune for your specific environment. Make sure to read the link:http://jgroups.org/manual-3.x/html/index.html[JGroups reference documentation], and play with the performance tests included in JGroups to make sure your network stack is setup appropriately. Don't forget to check also operating system level parameters, for example buffer sizes dedicated for networking. JGroups will log warning when it detects something wrong, but there is much more you can look into.

===== Using a CacheStore
Currently all CacheStore implementations provided by Infinispan have a significant slowdown; we hope to resolve that soon but for the time being if you need high performance on writes with the Lucene Directory the best option is to disable any CacheStore; the second best option is to configure the CacheStore as _async_ . If you only need to load a Lucene index from read-only storage, see the above description for _org.infinispan.lucene.cachestore.LuceneCacheLoader_ .

===== Apply standard Lucene tuning
All known options of Lucene apply to the Infinispan Lucene Directory as well; of course the effect might be less significant in some cases, but you should definitely read the link:http://lucene.apache.org/core/index.html[Apache Lucene documentation] .

===== Disable batching and transactions
Early versions required Infinispan to have batching or transactions enabled. This is no longer a requirement, and in fact disabling them should provide little improvement in performance.

===== Set the right chunk size
The chunk size can be specified using the link:{javadocroot}/org/infinispan/lucene/directory/DirectoryBuilder.html[DirectoryBuilder] fluent API. To correctly set this variable you need to estimate what the expected size of your segments is; generally this is trivial by looking at the file size of the index segments generated by your application when it's using the standard FSDirectory. You then have to consider:

* The chunk size affects the size of internally created buffers, and large chunk sizes will cause memory usage to grow. Also consider that during index writing such arrays are frequently allocated.
* If a segment doesn't fit in the chunk size, it's going to be fragmented. When searching on a fragmented segment performance can't peak.

Using the _org.apache.lucene.index.IndexWriterConfig_ you can tune your index writing to _approximately_ keep your segment size to a reasonable level, from there then tune the chunksize, after having defined the chunksize you might want to revisit your network configuration settings.

==== Demo

There is a simple command-line demo of its capabilities distributed with Infinispan under demos/lucene-directory; make sure you grab the "Binaries, server and demos" package from download page, which contains all demos.

Start several instances, then try adding text in one instance and searching for it on the other. The configuration is not tuned at all, but should work out-of-the box without any changes. If your network interface has multicast enabled, it will cluster across the local network with other instances of the demo.

==== Additional Links
* Issue tracker: link:https://jira.jboss.org/browse/ISPN/component/12312732[]
* Source code: link:https://github.com/infinispan/infinispan/tree/master/lucene/lucene-directory/src/main/java/org/infinispan/lucene[]

=== Directory Provider for Hibernate Search

Hibernate Search applications can use Infinispan as a directory provider, taking advantage of Infinispan's distribution and low latency capabilities to store the Lucene indexes.

==== Maven dependencies

.pom.xml
[source,xml,subs=attributes]
----
<dependency>
   <groupId>org.infinispan</groupId>
   <artifactId>infinispan-directory-provider</artifactId>
   <version>{infinispanversion}</version>
</dependency>

----

==== How to use it

The directory provider alias is _"infinispan"_, and to enable it for an index, the following property should be in the link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#configuration[Hibernate Search configuration]:

----
hibernate.search.MyIndex.directory_provider = infinispan
----

to enable it by default for all indexes:

----
hibernate.search.default.directory_provider = infinispan
----

The Infinispan cluster will start with a link:https://github.com/infinispan/infinispan/blob/master/lucene/directory-provider/src/main/resources/default-hibernatesearch-infinispan.xml[default configuration], see below how to override it.

==== Configuration

Optional properties allow for a custom Infinispan configuration or to use an existent _EmbeddedCacheManager_:

[options="header"]
|===============
|Property|Description|Example value
|hibernate.search.infinispan.configuration_resourcename| Custom configuration for Infinispan | config/infinispan.xml
|hibernate.search.infinispan.configuration.transport_override_resourcename| Overrides the JGroups stack in the Infinispan configuration file | jgroups-ec2.xml
|hibernate.search.infinispan.cachemanager_jndiname| Specifies the JNDI name under which the _EmbeddedCacheManager_ to use is bound. Will cause the properties above to be ignored when present| java:jboss/infinispan/container/hibernate-search
|===============

==== Architecture considerations

The same limitations presented in the Lucene Directory apply here, meaning the index will be shared across several nodes and only one _IndexWriter_ can have the lock.

One common strategy is to use Hibernate Search's JMS Master/Slave or JGroups backend together with the Infinispan directory provider: instead of sending updates directly to the index, they are sent to a JMS queue or JGroups channel and a single node applies all the changes on behalf of all other nodes.

Refer to the link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/[Hibernate Search documentation] for instructions on how to setup JMS or JGroups backends.

=== JPA/Hibernate 2L Cache

If you're unfamiliar with JPA/Hibernate Second Level Caching, please read link:https://docs.jboss.org/hibernate/orm/5.2/userguide/html_single/Hibernate_User_Guide.html#caching[this guide] which explains the different types of data that can be cached.

.On Caching
NOTE: Query result caching, or entity caching, _may or may not improve_ application performance. Be sure to benchmark your application with and without caching.

How to configure Infinispan to be the second level cache provider varies slightly depending on the deployment scenario:

==== Single Node Local

In standalone library mode, a JPA/Hibernate application runs inside a Java SE application or inside containers that don't offer Infinispan integration.

===== Single Node

Enabling Infinispan second level cache provider inside a JPA/Hibernate application that runs in single node is very straightforward.
First, make sure the Hibernate Infinispan cache provider (and its dependencies) are available in the classpath, then modify the persistence.xml to include these properties:

[source,xml]
----
<persistence-unit name="...">
   ...
   <shared-cache-mode>ENABLE_SELECTIVE</shared-cache-mode>
   <properties>
      ...
      <!-- Use Infinispan second level cache provider -->
      <property name="hibernate.cache.region.factory_class"
                value="org.hibernate.cache.infinispan.InfinispanRegionFactory"/>

      <!-- Optional: Force using local configuration when only using a single node.
           Otherwise a clustered configuration is loaded. -->
      <property name="hibernate.cache.infinispan.cfg"
                value="org/hibernate/cache/infinispan/builder/infinispan-configs-local.xml"/>

      <property name="hibernate.cache.use_second_level_cache" value="true" />

      <property name="hibernate.cache.use_query_cache" value="true" />
   </properties>
</persistence-unit>
----

On top of enabling the general Hibernate options to enable second level caching, plugging in Infinispan as second-level cache provider requires at the bare minimum that `hibernate.cache.region.factory_class` is set to `org.hibernate.cache.infinispan.InfinispanRegionFactory`.

By default, Infinispan second-level cache provider uses an Infinispan configuration that's designed for clustered environments.
However, since this section is focused on running Infinispan second-level cache provider in a single node, an Infinispan configuration designed for local environments is recommended.
To enable that configuration, set `hibernate.cache.infinispan.cfg` to `org/hibernate/cache/infinispan/builder/infinispan-configs-local.xml` value.

The next section focuses on analysing how the default local configuration works.

===== Default Local Configuration

Infinispan second-level cache provider comes with a configuration designed for local, single node, environments.
These are the characteristics of such configuration:

* Entities, collections, queries and timestamps are stored in non-transactional local caches.

* Entities and collections query caches are configured with the following eviction settings.
You can change these settings on a per entity or collection basis or per individual entity or collection type.
More information in the <<integrations:infinispan-2lc-advanced,Advanced Configuration>> section below.
 - Eviction wake up interval is 5 seconds.
 - Max number of entries are 10,000
 - Max idle time before expiration is 100 seconds
 - Default eviction algorithm is LRU, least recently used.

* _No eviction/expiration is configured for timestamp caches_, nor it's allowed.

==== Multi Node Cluster

When running a JPA/Hibernate in a multi-node environment and enabling second-level cache, it is necessary to cluster the second-level cache so that cache consistency can be guaranteed.
Clustering the Infinispan second-level cache provider is as simple as adding the following properties:

[source,xml]
----
<persistence-unit name="...">
   ...
   <shared-cache-mode>ENABLE_SELECTIVE</shared-cache-mode>
   <properties>
      ...
      <!-- Use Infinispan second level cache provider -->
      <property name="hibernate.cache.region.factory_class"
                value="org.hibernate.cache.infinispan.InfinispanRegionFactory"/>

      <property name="hibernate.cache.use_second_level_cache" value="true" />

      <property name="hibernate.cache.use_query_cache" value="true" />
   </properties>
</persistence-unit>
----

As with the standalone local mode, on top of enabling the general Hibernate options to enable second level caching, plugging in Infinispan as second-level cache provider requires at the bare minimum that `hibernate.cache.region.factory_class` is set to `org.hibernate.cache.infinispan.InfinispanRegionFactory`.

However, the default Infinispan configuration used by the second-level cache provider is already configured to work in a cluster environment, so no need to add any extra properties.

The next section focuses on analysing how the default cluster configuration works.

===== Default Cluster Configuration [[integrations:infinispan-2lc-cluster-configuration]]

Infinispan second-level cache provider default configuration is designed for multi-node clustered environments.
The aim of this section is to explain the default settings for each of the different global data type caches (entity, collection, query and timestamps), why these were chosen and what are the available alternatives.
These are the characteristics of such configuration:

*  For all entities and collections, whenever a new _entity or collection is read from database_ and needs to be cached, _it's only cached locally_ in order to reduce intra-cluster traffic.
This option cannot be changed.

*  All _entities and collections are configured to use a synchronous invalidation_ as clustering mode.
This means that when an entity is updated, the updated cache will send a message to the other members of the cluster telling them that the entity has been modified.
Upon receipt of this message, the other nodes will remove this data from their local cache, if it was stored there.
This option can be changed to use replication by configuring entities or collections to use `replicated-entity` cache but it's generally not a recommended choice.
How to change this option is explained in the <<integrations:infinispan-2lc-advanced,Advanced Configuration>> section.

*  All _entities and collections have initial state transfer disabled_ since there's no need for it.

* Entities and collections are configured with the following eviction settings.
You can change these settings on a per entity or collection basis or per individual entity or collection type.
More information in the <<integrations:infinispan-2lc-advanced,Advanced Configuration>> section below.
 - Eviction wake up interval is 5 seconds.
 - Max number of entries are 10,000
 - Max idle time before expiration is 100 seconds
 - Default eviction algorithm is LRU, least recently used.

*  The query cache is configured so that _queries are only cached locally_ .
Alternatively, you can configure query caching to use replication by selecting the `replicated-query` as query cache name.
However, replication for query cache only makes sense if, and only if, all of this conditions are true:
 - Performing the query is quite expensive.
 - The same query is very likely to be repeatedly executed on different cluster nodes.
 - The query is unlikely to be invalidated out of the cache (Note: Hibernate must aggressively invalidate query results from the cache any time any instance of one of the entity types targeted by the query. All such query results are invalidated, even if the change made to the specific entity instance would not have affected the query result)

*  _query cache_ uses the _same eviction/expiration settings as for entities/collections_.

*  _query cache has initial state transfer disabled_ . It is not recommended that this is enabled.

*  The _timestamps cache is configured with asynchronous replication_ as clustering mode.
Local or invalidated cluster modes are not allowed, since all cluster nodes must store all timestamps.
As a result, _no eviction/expiration is allowed for timestamp caches either_.

IMPORTANT: Asynchronous replication was selected as default for timestamps cache for performance reasons.
A side effect of this choice is that when an entity/collection is updated, for a very brief period of time stale queries might be returned.
It's important to note that due to how Infinispan deals with asynchronous replication, stale queries might be found even query is done right after an entity/collection update on same node.


==== Inside Wildfly or JBoss Application Server

In WildFly or JBoss Application Server 6+, Infinispan is the default second level cache provider for JPA/Hibernate.
You can find details about its configuration in link:{wildflydocroot}/JPA%20Reference%20Guide[the JPA reference guide], in particular, in the link:{wildflydocroot}/JPA%20Reference%20Guide#JPAReferenceGuide-UsingtheInfinispansecondlevelcache[second level cache] section.

The default second-level cache configurations used by Wildfly or JBoss Application Server match the configurations explained above both for local and clustered environments.
So, an Infinispan based second-level cache should behave exactly the same standalone and within containers that provide Infinispan second-level cache as default for JPA/Hibernate.

IMPORTANT: Remember that if deploying to Wildfly or Application Server, the way advanced configured is defined changes slightly since the properties must include deployment information.
Check the <<integrations:infinispan-2lc-advanced,Advanced Configuration>> section for more details.

Infinispan based Hibernate second-level cache provider was developed as part of Hibernate 3.5 release and so it currently only works within JBoss Application Server 6 or higher.
Hibernate 3.5 is not designed to work with JBoss Application Server 5.x or lower.
To be able to run Infinispan based Hibernate second-level cache provider in a lower JBoss Application Server version such as 5.1, the Infinispan second-level cache module would require porting to Hibernate 3.3.

TIP: Looking to integrate Infinispan with Hibernate in JBoss AS/EAP 5.x?  <<integrations:infinispan-2lc-as5,Read this section>>.


==== Advanced Configuration [[integrations:infinispan-2lc-advanced]]
Infinispan has the capability of exposing statistics via JMX and since Hibernate 3.5.0.Beta4, you can enable such statistics from the Hibernate/JPA configuration file.
By default, Infinispan statistics are turned off but when these are disabled via the following method, statistics for the Infinispan Cache Manager and all the managed caches (entity, collection, etc) are enabled:

[source,xml]
----
<property name="hibernate.cache.infinispan.statistics" value="true"/>
----

For each Hibernate cache data types, Infinispan cache region factory has defined a default cache name to look up in either the default, or the user defined, Infinispan cache configuration file.
These default values can be found in the link:http://docs.jboss.org/hibernate/orm/5.2/javadocs/constant-values.html#org.hibernate.cache.infinispan.InfinispanRegionFactory.INFINISPAN_CONFIG_RESOURCE_PROP[Infinispan cache provider javadoc] . You can change these cache names using the following properties:

[source,xml]
----
<property name="hibernate.cache.infinispan.entity.cfg"
   value="custom-entity"/>
<property name="hibernate.cache.infinispan.collection.cfg"
   value="custom-collection"/>
<property name="hibernate.cache.infinispan.query.cfg"
   value="custom-collection"/>
<property name="hibernate.cache.infinispan.timestamp.cfg"
   value="custom-timestamp"/>
----

One of the key improvements brought in by Infinispan is the fact that cache instances are more lightweight than they used to be in JBoss Cache.
This has enabled a radical change in the way entity/collection type cache management works.
With the Infinispan cache provider, each entity/collection type gets each own cache instance, whereas in old JBoss Cache based cache providers, all entity/collection types would be sharing the same cache instance.
As a result of this, locking issues related to updating different entity/collection types concurrently are avoided completely.

This also has an important bearing on the meaning of `hibernate.cache.infinispan.entity.cfg` and `hibernate.cache.infinispan.collection.cfg` properties.
These properties define the template cache name that should be used for all entity/collection data types.
So, with the above `hibernate.cache.infinispan.entity.cfg` configuration, when a region needs to be created for entity `com.acme.Person`, the cache instance to be assigned to this entity will be based on a "custom-entity" named cache.

On top of that, this finer grained cache definition enables users to define cache settings on a per entity/collection basis.
For example:

[source,xml]
----
<property name="hibernate.cache.infinispan.com.acme.Person.cfg"
   value="person-entity"/>
<property name="hibernate.cache.infinispan.com.acme.Person.addresses.cfg"
   value="addresses-collection"/>
----

IMPORTANT: For any entity or collection specific properties, if you are
running within JBoss Application Server, JBoss EAP, or Widlfly, providing just
the entity name is not enough. You need to add unit name and deployment name
as well to each property in the following format:
`hibernate.cache.infinispan.<warname>.<unitname>.<FQN of entity>.....`

Here, we're configuring the Infinispan cache provider so that for `com.acme.Person` entity type, the cache instance assigned will be based on a `person-entity` named cache.
For `com.acme.Person.addresses` collection type, the cache instance assigned will be based on a `addresses-collection` named cache.
If either of these two named caches did not exist in the Infinispan cache configuration file, the cache provider would create a cache instance for `com.acme.Person` entity and `com.acme.Person.addresses` collection based on the default cache in the configuration file.

Furthermore, thanks to the excellent feedback from the Infinispan community, we've decided to allow users to define the most commonly tweaked Infinispan cache parameters via `hibernate.cfg.xml` or `persistence.xml`, for example eviction/expiration settings.
So, with the Infinispan cache provider, you can configure eviction/expiration this way:

[source,xml]
----
<property name="hibernate.cache.infinispan.entity.eviction.strategy"
   value= "LRU"/>
<property name="hibernate.cache.infinispan.entity.eviction.wake_up_interval"
   value= "2000"/>
<property name="hibernate.cache.infinispan.entity.eviction.max_entries"
   value= "5000"/>
<property name="hibernate.cache.infinispan.entity.expiration.lifespan"
   value= "60000"/>
<property name="hibernate.cache.infinispan.entity.expiration.max_idle"
   value= "30000"/>
----

With the above configuration, you're overriding whatever eviction/expiration settings were defined for the default entity cache name in the Infinispan cache configuration used, regardless of whether it's the default one or user defined.
More specifically, we're defining the following:

* All entities to use LRU eviction strategy
* The eviction thread to wake up every 2000 milliseconds
* The maximum number of entities for each entity type to be 5000 entries
* The lifespan of each entity instance to be 600000 milliseconds
* The maximum idle time for each entity instance to be 30000

You can also override eviction/expiration settings on a per entity/collection type basis in such way that the overriden settings only afftect that particular entity (i.e. `com.acme.Person`) or collection type (i.e. `com.acme.Person.addresses`).
For example:

[source,xml]
----
<property name="hibernate.cache.infinispan.com.acme.Person.eviction.strategy"
   value= "LIRS"/>
<property name="hibernate.cache.infinispan.com.acme.Person.eviction.wake_up_interval"
   value= "2500"/>
<property name="hibernate.cache.infinispan.com.acme.Person.eviction.max_entries"
   value= "5500"/>
<property name="hibernate.cache.infinispan.com.acme.Person.expiration.lifespan"
   value= "65000"/>
<property name="hibernate.cache.infinispan.com.acme.Person.expiration.max_idle"
   value= "35000"/>
----

The aim of these configuration capabilities is to reduce the number of files needed to modify in order to define the most commonly tweaked parameters.
So, by enabling eviction/expiration configuration on a per generic Hibernate data type or particular entity/collection type via `hibernate.cfg.xml` or `persistence.xml`, users don't have to touch to Infinispan's cache configuration file any more.
We believe users will like this approach and so, if you there are any other Infinispan parameters that you often tweak and these cannot be configured via XML configuration, please let the Infinispan team know by sending an email to infinispan-dev@lists.jboss.org.

Please note that query/timestamp caches work the same way they did with JBoss Cache based cache providers.
In other words, there's a query cache instance and timestamp cache instance shared by all.
It's worth noting that eviction/expiration settings are allowed for query cache but not for timestamp cache.
So configuring an eviction strategy other than `NONE` for timestamp cache would result in a failure to start up.

Finally, from Hibernate 3.5.4 and 3.6 onwards, queries with specific cache region names are stored under matching cache instances.
This means that you can now set query cache region specific settings.
For example, assuming you had a query like this:

[source,java]
----
Query query = session.createQuery(
  "select account.branch from Account as account where account.holder = ?");
query.setCacheable(true);
query.setCacheRegion("AccountRegion");

----

The query would be stored under "AccountRegion" cache instance and users could control settings in similar fashion to what was done with entities and collections.
So, for example, you could define specific eviction settings for this particular query region doing something like this:

[source,xml]
----
<property name="hibernate.cache.infinispan.AccountRegion.eviction.strategy"
   value= "FIFO"/>
<property name="hibernate.cache.infinispan.AccountRegion.eviction.wake_up_interval"
   value= "10000"/>
----


==== Handling custom identifiers types

When custom identifier types are used in Hibernate/JPA entities, specially in
the case of composite identifiers, the resulting cache keys can end up holding
references to `SessionFactory` instances. Serializing those properly in a
clustered environment depends on being able to resolve the proper
`SessionFactory` reference on deserialization, which can happen based on UUID
(same JVM) or name (across JVMs).

When the resolution does not succeed, it's common to see errors similar to this:

[source,java]
----
java.io.InvalidObjectException: Could not find a SessionFactory [uuid=0d0cdf26-dfe6-4285-9725-dfaa4821ecba,name=null]
    at org.hibernate.internal.SessionFactoryImpl.locateSessionFactoryOnDeserialization(SessionFactoryImpl.java:1781)
    at org.hibernate.internal.SessionFactoryImpl.readResolve(SessionFactoryImpl.java:1761)
----

The way to get around these error is by locking down the name of the `SessionFactory`
across JVMs. This can be done by adding the following properties in the
clustered application's configuration:

[source,java]
----
hibernate.session_factory_name = MySessionFactory
hibernate.session_factory_name_is_jndi = false
----

TIP: These properties are not necessary if deploying in JBoss Application
Server, Wildfly or EAP containers, since the integration code already populates
session factory name based on deployment unit information.

==== Using Infinispan as remote Second Level Cache?
Lately, several questions ( link:http://community.jboss.org/message/575814#575814[here] and link:http://community.jboss.org/message/585841#585841[here] ) have appeared in the Infinispan user forums asking whether it'd be possible to have an Infinispan second level cache that instead of living in the same JVM as the Hibernate code, it resides in a remote server, i.e. an Infinispan Hot Rod server. It's important to understand that trying to set up second level cache in this way is generally not a good idea for the following reasons:


* The purpose of a JPA/Hibernate second level cache is to store entities/collections recently retrieved from database or to maintain results of recent queries. So, part of the aim of the second level cache is to have data accessible locally rather than having to go to the database to retrieve it everytime this is needed. Hence, if you decide to set the second level cache to be remote as well, you're losing one of the key advantages of the second level cache: the fact that the cache is local to the code that requires it.


* Setting a remote second level cache can have a negative impact in the overall performance of your application because it means that cache misses require accessing a remote location to verify whether a particular entity/collection/query is cached. With a local second level cache however, these misses are resolved locally and so they are much faster to execute than with a remote second level cache.

There are however some edge cases where it might make sense to have a remote second level cache, for example:


* You are having memory issues in the JVM where JPA/Hibernate code and the second level cache is running. Off loading the second level cache to remote Hot Rod servers could be an interesting way to separate systems and allow you find the culprit of the memory issues more easily.


* Your application layer cannot be clustered but you still want to run multiple application layer nodes. In this case, you can't have multiple local second level cache instances running because they won't be able to invalidate each other for example when data in the second level cache is updated. In this case, having a remote second level cache could be a way out to make sure your second level cache is always in a consistent state, will all nodes in the application layer pointing to it.


* Rather than having the second level cache in a remote server, you want to simply keep the cache in a separate VM still within the same machine. In this case you would still have the additional overhead of talking across to another JVM, but it wouldn't have the latency of across a network. The benefit of doing this is that:


* Size the cache separate from the application, since the cache and the application server have very different memory profiles. One has lots of short lived objects, and the other could have lots of long lived objects.


*  To pin the cache and the application server onto different CPU cores (using _numactl_ ), and even pin them to different physically memory based on the NUMA nodes.


====  Infinispan as Hibernate 2nd-Level Cache in JBoss AS 5.x [[integrations:infinispan-2lc-as5]]
A JBoss AS 5.x application can be configured to use Infinispan 4.x as the Hibernate 2nd-level cache, replacing JBoss Cache.

1\. Add the attached jar files to the ear lib directory. These include the core 4.1.0.GA Infinispan jar (infinispan-core.jar), the Hibernate/Infinispan integration jar back-ported from Hibernate 3.5 (hibernate-infinispan-3.3.2.GA_CP03.jar), the JGroups jar required by Infinispan 4.1.0 (jgroups-2.10.0.GA.jar), and other required 3rd party jars (river-1.2.3.GA.jar, marshalling-api-1.2.3.GA.jar)

2\. Isolate the classloading to be ear-scoped by adding `META-INF/jboss-classloading.xml`

.META-INF/jboss-classloading.xml
[source,xml]
----
<classloading xmlns="urn:jboss:classloading:1.0" domain="simple-scoped" parent-first="false" />
----

3\. Configure persistence.xml to use Infinispan instead of JBoss Cache:

.persistence.xml
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<persistence xmlns="http://java.sun.com/xml/ns/persistence"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_1_0.xsd"
   version="1.0">
<persistence-unit name="jpa-test">
    <jta-data-source>java:/PostgresDS</jta-data-source>
        <properties>
            <property name="hibernate.dialect" value="org.hibernate.dialect.HSQLDialect" />

            <property name="hibernate.session_factory_name" value="SessionFactories/infinispan" />

            <property name="hibernate.cache.use_query_cache" value="true" />
            <property name="hibernate.cache.use_second_level_cache" value="true" />
            <property name="hibernate.generate_statistics" value="true" />
            <property name="hibernate.cache.use_structured_entries" value="true" />

            <property name="hibernate.cache.region_prefix" value="infinispan" />

            <property name="hibernate.show_sql" value="true" />

            <property name="hibernate.hbm2ddl.auto" value="validate" />

            <!-- Infinispan second level cache configuration -->
            <property name="hibernate.cache.region.factory_class" value="org.hibernate.cache.infinispan.InfinispanRegionFactory" />
        </properties>
    </persistence-unit>
</persistence>

----

===  Using Infinispan with Spring Boot

Infinispan Spring Boot Starters allow to easily turn on Infinispan and Spring integration.
More information might be found at link:https://github.com/infinispan/infinispan-spring-boot[Infinispan Spring Boot Starters Gihub page].

===  Using Infinispan as a Spring Cache provider
Starting with version 3.1, the link:http://spring.io/[Spring Framework] offers a link:http://docs.spring.io/spring-framework/docs/4.1.1.RELEASE/spring-framework-reference/html/cache.html[cache abstraction], enabling users to declaratively add caching support to applications via two simple annotations, `@Cacheable` and `@CacheEvict`.
While out of the box Spring's caching support is backed by link:http://ehcache.org[EHCache] it has been designed to easily support different cache providers.
To that end Spring defines a simple and straightforward SPI other caching solutions may implement.
Infinispan's very own spring modules do - amongst other things - exactly this and therefore users invested in Spring's programming model may easily have all their caching needs fulfilled through Infinispan.

Here's how.

==== Activating Spring Cache support
You activate Spring's cache support using xml:

[source,xml]
----
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:cache="http://www.springframework.org/schema/cache"
    xmlns:p="http://www.springframework.org/schema/p"
    xsi:schemaLocation="
        http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/cache http://www.springframework.org/schema/cache/spring-cache.xsd">

        <cache:annotation-driven />

</beans>

----

somewhere in your application context. This enable the cache annotations in Spring. Alternatively, it can be done programmatically:

[source,java]
----
@EnableCaching @Configuration
public class Config {
}

----

Now, you will need to add Infinispan and Spring integration module to your classpath. For Maven users this might be achieved by adding these dependencies:

.pom.xml for Spring 4 (embedded mode)
[source,xml]
----
    <dependencies>
        <dependency>
            <groupId>org.infinispan</groupId>
            <artifactId>infinispan-embedded</artifactId>
        </dependency>
        <dependency>
            <groupId>org.infinispan</groupId>
            <artifactId>infinispan-spring4-embedded</artifactId>
            <version>${version.spring}</version>
        </dependency>
        <!-- depending on a use case, one should use Spring Context or Spring Boot jars -->
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-context</artifactId>
            <version>${version.spring}</version>
        </dependency>
    </dependencies>
----

==== Telling Spring to use Infinispan as its caching provider
Spring cache provider SPI comprises two interfaces, `org.springframework.cache.CacheManager` and `org.springframework.cache.Cache` where a `CacheManager` serves as a factory for named `Cache` instances.
By default Spring will look at runtime for a `CacheManager` implementation having the bean name "cacheManager" in an application's application context. So by putting

[source,xml]
----

<!-- Infinispan cache manager -->
<bean id="cacheManager"
          class="org.infinispan.spring.provider.SpringEmbeddedCacheManagerFactoryBean"
          p:configurationFileLocation="classpath:/org/infinispan/spring/provider/sample/books-infinispan-config.xml" />

----

or using java config:

[source, java]
----
@EnableCaching
@Configuration
public class Config {

   @Bean
   public CacheManager cacheManager() {
      return new SpringEmbeddedCacheManager(infinispanCacheManager());
   }

   private EmbeddedCacheManager infinispanCacheManager() {
      return new DefaultCacheManager();
   }

}
----

somewhere in your application context you tell Spring to henceforth use Infinispan as its caching provider.

==== Adding caching to your application code
As outlined above enabling caching in your application code is as simple as adding `@Cacheable` and `@CacheEvict` to select methods. Suppose you've got a DAO for, say, books and you want book instances to be cached once they've been loaded from the underlying database using `BookDao#findBook(Integer bookId)`. To that end you annotate `findBook(Integer bookId)` with `@Cacheable`, as in

[source,java]
----

@Transactional
@Cacheable(value = "books", key = "#bookId")
Book findBook(Integer bookId) {...}

----

This will tell Spring to cache Book instances returned from calls to `findBook(Integer bookId)` in a named cache "books", using the parameter's "bookId" value as a cache key. Here, "#bookId" is an expression in the link:http://static.springsource.org/spring/docs/current/spring-framework-reference/html/expressions.html[Spring Expression Language] that evaluates to the `bookId` argument. If you don't specify the `key` attribute Spring will generate a hash from the supplied method arguments - in this case only `bookId` - and use that as a cache key. Essentially, you relinquish control over what cache key to use to Spring. Which may or may not be fine depending on your application's needs.Though the notion of actually deleting a book will undoubtedly seem alien and outright abhorrent to any sane reader there might come the time when your application needs to do just that. For whatever reason. In this case you will want for such a book to be removed not only from the underlying database but from the cache, too. So you annotate `deleteBook(Integer bookId)` with `@CacheEvict` as in

[source,java]
----

@Transactional
@CacheEvict(value = "books", key = "#bookId")
void deleteBook(Integer bookId) {...}

----

and you may rest assured that no stray books be left in your application once you decide to remove them.

==== Externalizing session using Spring Session

link:http://docs.spring.io/spring-session/docs/current/reference/html5[Spring Session] is a very convenient way to externalize user session into Infinispan cluster.

Spring Session integration allows to use both - embedded and client/server mode. Each mode requires using proper artifacts (`infinispan-spring4-embedded` or `infinispan-spring4-remote`).
An example is shown below:

[source,xml]
----
    <dependencies>
        <dependency>
            <groupId>org.infinispan</groupId>
            <artifactId>infinispan-embedded</artifactId>
        </dependency>
        <dependency>
            <groupId>org.infinispan</groupId>
            <artifactId>infinispan-spring4-embedded</artifactId>
            <version>${version.spring}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-context</artifactId>
            <version>${version.spring}</version>
        </dependency>
        <dependency>
           <groupId>org.springframework</groupId>
           <artifactId>spring-session</artifactId>
           <version>${version.spring}</version>
       </dependency>
       <dependency>
           <groupId>org.springframework</groupId>
           <artifactId>spring-web</artifactId>
           <version>${version.spring}</version>
       </dependency>
    </dependencies>
----

Spring Session integration has been based on Infinispan Spring Cache support so it requires creating a `SpringEmbeddedCacheManagerFactoryBean` or `SpringRemoteCacheManagerFactoryBean`.
The next step it to use `@EnableInfinispanEmbeddedHttpSession` or `@EnableInfinispanRemoteHttpSession` configuration annotation which turns on Spring Session.

`@EnableInfinispanEmbeddedHttpSession` or `@EnableInfinispanRemoteHttpSession` annotations have 2 optional parameters:

* maxInactiveIntervalInSeconds - which sets session expiration time in seconds. The default is set to `1800`.
* cacheName - cache name which is used for storing sessions. The default is set to `sessions`.

A complete, annotation based configuration example is shown below:

[source, java]
----
@EnableInfinispanEmbeddedHttpSession
@Configuration
public class Config {

   @Bean
   public SpringEmbeddedCacheManagerFactoryBean springCacheManager() {
      return new SpringEmbeddedCacheManagerFactoryBean();
   }

   //An optional configuration bean which is responsible for replacing the default cookie
   //for obtaining configuration.
   //For more information refer to Spring Session documentation.
   @Bean
   public HttpSessionStrategy httpSessionStrategy() {
      return new HeaderHttpSessionStrategy();
   }
}
----

==== Conclusion
Hopefully you enjoyed our quick tour of Infinispan's support for Spring's cache and session abstraction and saw how easy it is for all your caching woes to be taken care of by Infinispan. More information may be found in Spring's link:http://docs.spring.io/spring-framework/docs/4.1.1.RELEASE/spring-framework-reference/html/cache.html[reference documentation]. Also see link:http://spring.io/blog/2011/02/23/spring-3-1-m1-cache-abstraction[this link] - a very nice posting on the official Spring blog for a somewhat more comprehensive introduction to Spring's cache abstraction.

===  Infinispan modules for WildFly

As the Infinispan modules shipped with link:http://wildfly.org/[Wildfly application server] are tailored to its internal usage, it is recommend to install separate modules
if you want to use Infinispan in your application that is deployed to Wildfy. By installing these modules, it is possible to deploy user applications without packaging the Infinispan JARs within the deployments (WARs, EARs, etc), thus minimizing their size.
Also, there will be no conflict with Wildfly's internal modules since the slot will be different.

[[_Modules_installation_section]]
==== Installation

The modules for Wildfly are available in the link:http://infinispan.org/download/[downloads] section of our site. The zip should be extracted to `WILDFLY_HOME/modules`, so that for example the infinispan core module would be under `WILDFLY_HOME/modules/org/infinispan/core`.

==== Usage

If you are using Maven to build your application, mark the Infinispan dependencies as _provided_ and configure your artifact archiver to generate the appropriate MANIFEST.MF file:

.pom.xml
[source,xml,subs=attributes+]
----

<dependencies>
  <dependency>
    <groupId>org.infinispan</groupId>
    <artifactId>infinispan-core</artifactId>
    <version>{infinispanversion}</version>
    <scope>provided</scope>
  </dependency>
  <dependency>
    <groupId>org.infinispan</groupId>
    <artifactId>infinispan-cachestore-jdbc</artifactId>
    <version>{infinispanversion}</version>
    <scope>provided</scope>
  </dependency>
</dependencies>
<build>
  <plugins>
     <plugin>
       <groupId>org.apache.maven.plugins</groupId>
       <artifactId>maven-war-plugin</artifactId>
       <configuration>
         <archive>
           <manifestEntries>
             <Dependencies>org.infinispan.core:{infinispanslot} services, org.infinispan.cachestore.jdbc:{infinispanslot} services</Dependencies>
           </manifestEntries>
         </archive>
      </configuration>
    </plugin>
  </plugins>
</build>

----

The next section illustrates the manifest entries for different types of Infinispan's dependencies.

===== Infinispan core

In order expose only Infinispan core dependencies to your application, add the follow to the manifest:

.MANIFEST.MF
[source,subs=attributes]
----

Manifest-Version: 1.0
Dependencies: org.infinispan:{infinispanslot} services

----

===== Remote

If you need to connect to remote Infinispan servers via Hot Rod, including execution of remote queries, use the module ```org.infinispan.remote``` that exposes the needed dependencies conveniently:

.MANIFEST.MF
[source,subs=attributes]
----

Manifest-Version: 1.0
Dependencies: org.infinispan.remote:{infinispanslot} services

----

===== Embedded Query

For embedded querying, including the Infinispan Query DSL, Lucene and Hibernate Search Queries, add the following:

.MANIFEST.MF
[source,subs=attributes]
----

Manifest-Version: 1.0
Dependencies: org.infinispan:{infinispanslot} services, org.infinispan.query:{infinispanslot} services

----

===== Lucene Directory

Lucene users who wants to simple use Infinispan as a _org.apache.lucene.store.Directory_ don't need to add the query module, the entry below is sufficient:

.MANIFEST.MF
[source,subs=attributes]
----

Manifest-Version: 1.0
Dependencies: org.infinispan.lucene-directory:{infinispanslot}

----

===== Hibernate Search directory provider for Infinispan

The Hibernate Search directory provider for Infinispan is also contained within the Infinispan modules zip. It is not necessary to add an entry to the manifest file since the Hibernate Search module already has an optional dependency to it.
When choosing the Infinispan module zip to use, start by checking which Hibernate Search is in use, more details below.

====== Usage with Wildfy's internal Hibernate Search modules

The Hibernate Search module present in Wildfly 10.x has slot "5.5", which in turn has an optional dependency to `org.infinispan.hibernate-search.directory-provider:for-hibernatesearch-5.5`.
This dependency will be available once the Infinispan modules are <<_Modules_installation_section,installed>>.


====== Usage with other Hibernate Search modules

The module `org.hibernate.search:{infinispanslot}` distributed with Infinispan is to be used together with Infinispan Query only (querying data from caches), and should not be used by Hibernate ORM applications.
To use a Hibernate Search with a different version that is present in Wildfly, please consult the link:https://docs.jboss.org/hibernate/search/5.6/reference/en-US/html_single/#search-configuration-deploy-on-wildfly[Hibernate Search documentation].

Make sure that the chosen Hibernate Search optional slot for `org.infinispan.hibernate-search.directory-provider` matches the one distributed with Infinispan.

==== Troubleshooting

===== Enable logging

Enabling trace on `org.jboss.modules` can be useful to debug issues like `LinkageError` and `ClassNotFoundException`.
To enable it at runtime using the Wildfly CLI:

----
bin/jboss-cli.sh -c '/subsystem=logging/logger=org.jboss.modules:add'
bin/jboss-cli.sh -c '/subsystem=logging/logger=org.jboss.modules:write-attribute(name=level,value=TRACE)'

----
===== Print dependency tree

The following command can be used to print all dependencies for a certain module. For example, to obtain the tree for the module `org.infinispan:{infinispanslot}`, execute from `WILDFLY_HOME`:

[subs=attributes]
----
java -jar jboss-modules.jar -deptree -mp modules/ "org.infinispan:{infinispanslot}"

----
