==  Running on Cloud Services

=== Amazon Web Services
Infinispan can be used on the Amazon Web Service (AWS) platform and similar cloud based environment in several ways. As Infinispan uses JGroups as the underlying communication technology, the majority of the configuration work is done JGroups. The default auto discovery won't work on EC2 as multicast is not allowed, but JGroups provides several other discovery protocols so we only have to choose one.

==== TCPPing, GossipRouter, S3_PING
The TCPPing approach contains a static list of the IP address of each member of the cluster in the JGroups configuration file.
While this works it doesn't really help when cluster nodes are dynamically added to the cluster.

.Sample TCPPing configuration
[source,xml]
----
<config>
      <TCP bind_port="7800" />
      <TCPPING timeout="3000"
           initial_hosts="${jgroups.tcpping.initial_hosts:localhost[7800],localhost[7801]}"
           port_range="1"
           num_initial_members="3"/>
...
...
</config>
----

See link:$$http://community.jboss.org/wiki/JGroupsTCPPING$$[] for more information about TCPPing. 

==== GossipRouter
Another approach is to have a central server (Gossip, which each node will be configured to contact. This central server will tell each node in the cluster about each other node. 

The address (ip:port) that the Gossip router is listening on can be injected into the JGroups configuration used by Infinispan. To do this pass the gossip routers address as a system property to the JVM e.g. `-DGossipRouterAddress="10.10.2.4[12001]"` and reference this property in the JGroups configuration that Infinispan is using e.g.

.Sample TCPGOSSIP configuration
[source,xml]
----

<config>
    <TCP bind_port="7800" />
    <TCPGOSSIP timeout="3000" initial_hosts="${GossipRouterAddress}" num_initial_members="3" />
...
...
</config>

----

More on Gossip Router @ link:$$http://community.jboss.org/docs/DOC-10890$$[http://www.jboss.org/community/wiki/JGroupsGossipRouter] 

==== S3_PING
Finally you can configure your JGroups instances to use a shared storage to exchange the details of the cluster nodes. S3_PING was added to JGroups in 2.6.12 and 2.8, and allows the Amazon S3 to be used as the shared storage. It is experimental at the moment but offers another method of clustering without a central server. Be sure that you have signed up for Amazon S3 as well as EC2 to use this method.

.Sample S3PING configuration
[source,xml]
----
<config>
    <TCP bind_port="7800" />
    <S3_PING
            secret_access_key="replace this with you secret access key"
            access_key="replace this with your access key"
            location="replace this with your S3 bucket location" />
</config>

----

==== JDBC_PING
A similar approach to S3_PING, but using a JDBC connection to a shared database. On EC2 that is quite easy using Amazon RDS. See the link:$$http://community.jboss.org/wiki/JDBCPING$$[JDBC_PING Wiki page] for details. 

==  Using Kubernetes and OpenShift Rolling Updates

TBD!!!

==  Rolling upgrades

=== Kubernetes and OpenShift

For both Kubernetes and OpenShift, the Rolling Upgrade procedure is almost the same. It is based on a standard <<_Rolling_chapter,Rolling Upgrade procedure>> with small changes.

.Key differences when upgrading using OpenShift/Kubernetes are:
* When forming a new cluster, make sure you use labels. Labels can be used by link:$$https://github.com/jgroups-extras/jgroups-kubernetes$$[Kubernetes PING Protocol] (see `OPENSHIFT_KUBE_PING_LABELS` environment variable) and they allow controlling which nodes are assigned to which clusters.
* Depending on configuration, it is a good practice to use link:$$https://docs.openshift.org/latest/architecture/core_concepts/routes.html$$[OpenShift Routes] or link:$$http://kubernetes.io/docs/user-guide/ingress$$[Kubernetes Ingress API] to expose services to the clients. During the upgrade the Route (or Ingress) used by the clients can be altered to point to the new cluster.
* Invoking CLI commands can be done by using Kubernetes (`kubectl exec`) or OpenShift clients (`oc exec`). Here is an example: `oc exec <POD_NAME> -- '/opt/jboss/infinispan-server/bin/ispn-cli.sh' '-c' '--controller=$(hostname -i):9990' '/subsystem=datagrid-infinispan/cache-container=clustered/distributed-cache=default:disconnect-source(migrator-name=hotrod)'`

.Key differences when upgrading using the library mode:
* Client application needs to expose JMX. It usually depends on application and environment type but the easiest way to do it is to add the following switches into the Java boostrap script `-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<PORT>`.
* Connecting to the JMX can be done by forwarding ports. With OpenShift this might be achieved by using `oc port-forward` command whereas in Kubernetes by `kubectl port-forward`.

The last step in the Rolling Upgrade (removing a Remote Cache Store) needs to be performed differently. We need to use link:$$http://kubernetes.io/docs/user-guide/rolling-updates/$$[Kubernetes/OpenShift Rolling update] command and replace Pods configuration with the one which does not contain Remote Cache Store.